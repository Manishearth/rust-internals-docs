initSidebarItems({"mod":[["astconv_util","This module contains a simple utility routine used by both `typeck` and `const_eval`. Almost certainly this could (and should) be refactored out of existence."],["cfg","Module that constructs a control-flow graph representing an item. Uses `Graph` as the underlying representation."],["check_match",""],["const_eval",""],["const_qualif",""],["cstore",""],["dataflow","A module for propagating forward dataflow information. The analysis assumes that the items to be propagated can be represented as bits and thus uses bitvectors. Your job is simply to specify the so-called GEN and KILL bits for each expression."],["dead",""],["def",""],["def_id",""],["dependency_format","Resolution of mixing rlibs and dylibsWhen producing a final artifact, such as a dynamic library, the compiler has a choice between linking an rlib or linking a dylib of all upstream dependencies. The linking phase must guarantee, however, that a library only show up once in the object file. For example, it is illegal for library A to be statically linked to B and C in separate dylibs, and then link B and C into a crate D (because library A appears twice).The job of this module is to calculate what format each upstream crate should be used when linking each output type requested in this session. This generally follows this set of rules:With these constraints in mind, it's generally a very difficult problem to find a solution that's not \"all rlibs\" or \"all dylibs\". I have suspicions that NP-ness may come into the picture here...The current selection algorithm below looks mostly similar to:While not perfect, this algorithm should help support use-cases such as leaf dependencies being static while the larger tree of inner dependencies are all dynamic. This isn't currently very well battle tested, so it will likely fall short in some use cases.Currently, there is no way to specify the preference of linkage with a particular library (other than a global dynamic/static switch). Additionally, the algorithm is geared towards finding *any* solution rather than finding a number of solutions (there are normally quite a few)."],["effect","Enforces the Rust effect system. Currently there is just one effect, `unsafe`."],["entry",""],["expr_use_visitor","A different sort of visitor for walking fn bodies.  Unlike the normal visitor, which just walks the entire body in one shot, the `ExprUseVisitor` determines how expressions are being used."],["free_region","This file handles the relationships between free regions -- meaning lifetime parameters. Ordinarily, free regions are unrelated to one another, but they can be related via implied or explicit bounds.  In that case, we track the bounds using the `TransitiveRelation` type and use that to decide when one free region outlives another and so forth."],["infer","See the Book for more information."],["intrinsicck",""],["lang_items",""],["liveness","A classic liveness analysis based on dataflow over the AST.  Computes, for each local variable in a function, whether that variable is live at a given point.  Program execution points are identified by their id.Basic ideaThe basic model is that each local variable is assigned an index.  We represent sets of local variables using a vector indexed by this index.  The value in the vector is either 0, indicating the variable is dead, or the id of an expression that uses the variable.We conceptually walk over the AST in reverse execution order.  If we find a use of a variable, we add it to the set of live variables.  If we find an assignment to a variable, we remove it from the set of live variables.  When we have to merge two flows, we take the union of those two flows---if the variable is live on both paths, we simply pick one id.  In the event of loops, we continue doing this until a fixed point is reached.Checking initializationAt the function entry point, all variables must be dead.  If this is not the case, we can report an error using the id found in the set of live variables, which identifies a use of the variable which is not dominated by an assignment.Checking movesAfter each explicit move, the variable must be dead.Computing last usesAny use of the variable where the variable is dead afterwards is a last use.Implementation detailsThe actual implementation contains two (nested) walks over the AST. The outer walk has the job of building up the ir_maps instance for the enclosing function.  On the way down the tree, it identifies those AST nodes and variable IDs that will be needed for the liveness analysis and assigns them contiguous IDs.  The liveness id for an AST node is called a `live_node` (it's a newtype'd usize) and the id for a variable is called a `variable` (another newtype'd usize).On the way back up the tree, as we are about to exit from a function declaration we allocate a `liveness` instance.  Now that we know precisely how many nodes and variables we need, we can allocate all the various arrays that we will need to precisely the right size.  We then perform the actual propagation on the `liveness` instance.This propagation is encoded in the various `propagate_through_*()` methods.  It effectively does a reverse walk of the AST; whenever we reach a loop node, we iterate until a fixed point is reached.The `Users` structAt each live node `N`, we track three pieces of information for each variable `V` (these are encapsulated in the `Users` struct):`reader`: the `LiveNode` ID of some node which will read the value that `V` holds on entry to `N`.  Formally: a node `M` such that there exists a path `P` from `N` to `M` where `P` does not write `V`.  If the `reader` is `invalid_node()`, then the current value will never be read (the variable is dead, essentially).`writer`: the `LiveNode` ID of some node which will write the variable `V` and which is reachable from `N`.  Formally: a node `M` such that there exists a path `P` from `N` to `M` and `M` writes `V`.  If the `writer` is `invalid_node()`, then there is no writer of `V` that follows `N`.`used`: a boolean value indicating whether `V` is *used*.  We distinguish a *read* from a *use* in that a *use* is some read that is not just used to generate a new value.  For example, `x += 1` is a read but not a use.  This is used to generate better warnings.Special VariablesWe generate various special variables for various, well, special purposes. These are described in the `specials` struct:`exit_ln`: a live node that is generated to represent every 'exit' from the function, whether it be by explicit return, panic, or other means.`fallthrough_ln`: a live node that represents a fallthrough`no_ret_var`: a synthetic variable that is only 'read' from, the fallthrough node.  This allows us to detect functions where we fail to return explicitly.`clean_exit_var`: a synthetic variable that is only 'read' from the fallthrough node.  It is only live if the function could converge via means other than an explicit `return` expression. That is, it is only dead if the end of the function's block can never be reached. It is the responsibility of typeck to ensure that there are no `return` expressions in a function declared as diverging."],["mem_categorization","CategorizationThe job of the categorization module is to analyze an expression to determine what kind of memory is used in evaluating it (for example, where dereferences occur and what kind of pointer is dereferenced; whether the memory is mutable; etc)Categorization effectively transforms all of our expressions into expressions of the following forms (the actual enum has many more possibilities, naturally, but they are all variants of these base forms):Imagine a routine ToAddr(Expr) that evaluates an expression and returns an address where the result is to be found.  If Expr is an lvalue, then this is the address of the lvalue.  If Expr is an rvalue, this is the address of some temporary spot in memory where the result is stored.Now, cat_expr() classifies the expression Expr and the address A=ToAddr(Expr) as follows:cat: what kind of expression was this?  This is a subset of the full expression forms which only includes those that we care about for the purpose of the analysis. mutbl: mutability of the address A ty: the type of data found at the address A The resulting categorization tree differs somewhat from the expressions themselves.  For example, auto-derefs are explicit.  Also, an index a[b] is decomposed into two operations: a dereference to reach the array data and then an index to jump forward to the relevant item.By-reference upvarsOne part of the translation which may be non-obvious is that we translate closure upvars into the dereference of a borrowed pointer; this more closely resembles the runtime translation. So, for example, if we had:Then when we categorize `x` (*within* the closure) we would yield a result of `*x'`, effectively, where `x'` is a `Categorization::Upvar` reference tied to `x`. The type of `x'` will be a borrowed pointer."],["pat_util",""],["privacy","A pass that checks to make sure private fields and methods aren't used outside their scopes. This pass will also generate a set of exported items which are available for use externally when compiled as a library."],["reachable",""],["recursion_limit",""],["region","This file actually contains two passes related to regions.  The first pass builds up the `scope_map`, which describes the parent links in the region hierarchy.  The second pass infers which types must be region parameterized.Most of the documentation on regions can be found in `middle/infer/region_inference/README.md`"],["resolve_lifetime","Name resolution for lifetimes.Name resolution for lifetimes follows MUCH simpler rules than the full resolve. For example, lifetime names are never exported or used between functions, and they operate in a purely top-down way. Therefore we break lifetime name resolution into a separate pass."],["stability","A pass that annotates every item and method with its stability level, propagating default levels lexically from parent to children ast nodes."],["subst",""],["traits","Trait Resolution. See the Book for more."],["ty",""],["weak_lang_items","Validity checking for weak lang items"]]});